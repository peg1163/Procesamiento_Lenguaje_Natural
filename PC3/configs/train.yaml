model:
  d_model: 256
  n_heads: 4
  n_layers: 4
  d_ff: 1024
  dropout: 0.1
  vocab_size: 128
  max_seq_len: 256
  posenc_type: "rope"   

train:
  batch_size: 32
  lr: 3.0e-4        
  num_steps: 5000
  warmup_steps: 100
  weight_decay: 0.01
  grad_clip: 1.0
  eval_every: 500
  seed: 42
  device: "cuda"


data:
  dataset: "tinyshakespeare"
  path: "data/raw/input.txt"
  seq_len: 256
  val_ratio: 0.01
